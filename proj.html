<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>proj</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="proj.css" />
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<hr style="border: none; border-top: 5px solid black;">
<h1 style="text-align: center;">
Neural Collaberative Filtering
</h1>
<hr style="border: none; border-top: 1px solid black;">
<br> <br>
<center>
<strong style="font-size: 12pt;">Anonymous Author(s)</strong>
</center>
<p style="text-align: center; font-size: 10pt; line-height: 11pt;">
Affiliation <br> Address <br> email
</p>
<br>
<center>
<strong style="font-size: 12pt;">Abstract</strong>
</center>
<p style="text-align: justify; margin-left: 3pc; margin-right: 3pc; font-size: 10pt; line-height: 11pt;">
Your abstract text goes here. This paragraph will be indented 1/2 inch
on both sides, with a vertical spacing of 11 points (leading). It is
also in 10-point type, as specified. bla lablabc labal balab laba lbala
balba labl abalbala balab laba lbalb alabl abalbal abalba lablabalb
alabl aba lbala blabalab
</p>
<br> <strong style="font-size: 12pt;">Background</strong> <br> <br>
<p style="text-align: justify; font-size: 10pt; line-height: 11pt;">
Collaborative filtering is a method used in recommendation systems to
suggest items to users based on the preferences and behaviors of other
users. Basically assuming that if User <span
class="math inline">\(A\)</span> liked something and User <span
class="math inline">\(B\)</span> has similar taste to User <span
class="math inline">\(A\)</span> then User <span
class="math inline">\(B\)</span> will also like something User <span
class="math inline">\(A\)</span> liked.
</p>
<p style="text-align: justify; font-size: 10pt; line-height: 11pt;">
Matrix factorization models are used to discover latent features that
explain the patterns in user-item interactions. We basically have a
matrix <span class="math inline">\(R\)</span> where rows <span
class="math inline">\((m)\)</span> represent the users and the columns
<span class="math inline">\((n)\)</span> represent the items. We then
want to factorize <span class="math inline">\(R\)</span> into two
smaller matrices <span class="math inline">\((P)\)</span> an <span
class="math inline">\(m * k\)</span> where each row represents a user
and the column represents a latent feature. For the item matrix <span
class="math inline">\(Q n * k\)</span> where each row represents an item
and each column represents a latent feature of the item. Then the
factorization attempts to approximate the matrix <span
class="math inline">\(R\)</span> from <span class="math inline">\(P *
Q^T\)</span>. The latent factors or hidden features are the things which
get learned that explain the observed interaction between users and
items.
</p>
<p style="text-align: justify; font-size: 10pt; line-height: 11pt;">
Once the latent features are learned the dot product is used to predict
(rank) the rating of between the users and items. Where the interaction
between a user and an item can be estimated by measuring how well the
latent feature vectors for that user and that item match or align with
each other (the dot product). When there is a high dot product it means
that the latent features for a user and an item align well, while a low
dot product means that the vectors do not align.
</p>
<p style="text-align: justify; font-size: 10pt; line-height: 11pt;">
However using the dot product does have some drawbacks. The dot product
assumes that the user-item interactions are linearly dependent on the
latent features. If two items are similar, the dot product assumes that
the user’s preference for both items is simply the sum of their
preferences for the individual latent features. The dot product assumes
that user preferences can be captured by a single, linear combination of
item attributes (represented by the item’s latent feature vector).
</p>
<br> <strong style="font-size: 12pt;">Model Architecture</strong> <br>
<br>
<p style="font-size: 10pt; line-height: 11pt;">
bla lablabc labal balab laba lbala balba labl abalbala balab laba lbalb
alabl abalbal abalba lablabalb alabl aba lbala blabalab bla lablabc
labal balab laba lbala balba labl abalbala balab laba lbalb alabl
abalbal abalba lablabalb alabl aba lbala blabalab
</p>
<br> <strong style="font-size: 12pt;">Minimal CPU-Ready Working
Example</strong> <br> <br>
<p style="font-size: 10pt; line-height: 11pt;">
bla lablabc labal balab laba lbala balba labl abalbala balab laba lbalb
alabl abalbal abalba lablabalb alabl aba lbala blabalab bla lablabc
labal balab laba lbala balba labl abalbala balab laba lbalb alabl
abalbal abalba lablabalb alabl aba lbala blabalabbla lablabc labal balab
laba lbala balba labl abalbala balab laba lbalb alabl abalbal abalba
lablabalb alabl aba lbala blabalab bla lablabc labal balab laba lbala
balba labl abalbala balab laba lbalb alabl abalbal abalba lablabalb
alabl aba lbala blabalab
</p>
<br> <strong style="font-size: 12pt;">Discussion</strong> <br> <br>
<p style="font-size: 10pt; line-height: 11pt;">
bla lablabc labal balab laba lbala balba labl abalbala balab laba lbalb
alabl abalbal abalba lablabalb alabl aba lbala blabalab bla lablabc
labal balab laba lbala balba labl abalbala balab laba lbalb alabl
abalbal abalba lablabalb alabl aba lbala blabalab bla lablabc labal
balab laba lbala balba labl abalbala balab laba lbalb alabl abalbal
abalba lablabalb alabl aba lbala blabalab bla lablabc labal balab laba
lbala balba labl abalbala balab laba lbalb alabl abalbal abalba
lablabalb alabl aba lbala blabalab
</p>
<br> <strong style="font-size: 12pt;">Contribution</strong> <br> <br>
<p style="font-size: 10pt; line-height: 11pt;">
bla lablabc labal balab laba lbala balba labl abalbala balab laba lbalb
alabl abalbal abalba lablabalb alabl aba lbala blabalab bla lablabc
labal balab laba lbala balba labl abalbala balab laba lbalb alabl
abalbal abalba lablabalb alabl aba lbala blabalab
</p>
<br> <strong style="font-size: 12pt;">References</strong> <br> <br>
<p style="font-size: 10pt; line-height: 11pt;">
Any choice of citation style is acceptable as long as you are consistent
It is permissible to reduce the font size to small (9 point) when
listing the references.Note that the Reference section does not count
towards the page limit.
</p>
<p style="font-size: 10pt; line-height: 11pt;">
[1] Alexander, J.A. &amp; Mozer, M.C. (1995) Template-based algorithms
for connectionist rule extraction. In G.Tesauro, D.S. Touretzky and T.K.
Leen (eds.), <i>Advances in Neural Information Processing Systems
7</i>,pp. 609–616. Cambridge, MA: MITPress.
</p>
<p style="font-size: 10pt; line-height: 11pt;">
[2] Bower, J.M. &amp; Beeman, D. (1995) <i>The Book of GENESIS:
Exploring Realistic Neural Models with the GEneral NEural SImulation
System.</i> New York: TELOS/Springer–Verlag.
</p>
<p style="font-size: 10pt; line-height: 11pt;">
[3] Hasselmo, M.E., Schnell, E. &amp; Barkai, E. (1995) Dynamics of
learning and recall at excitatory recurrent synapses and cholinergic
modulation in rat hippocampal region CA3. <i>Journal of Neuroscience</i>
<strong>15</strong>(7):5249-5262.
</p>
<br> <strong style="font-size: 12pt;">Appendix</strong> <br> <br>
<p style="font-size: 10pt; line-height: 11pt;">
Optionally include supplemental material (complete proofs additional
experiments and plots) in appendix. All such materials <strong>SHOULD be
included in the main submission.<strong>
</p>
</body>
</html>
